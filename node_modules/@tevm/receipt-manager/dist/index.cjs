'use strict';

var utils = require('@tevm/utils');
var blockchain = require('@tevm/blockchain');
var rlp = require('@tevm/rlp');

// src/createMapDb.js
var typeToId = {
  Receipts: 0,
  TxHash: 1,
  SkeletonBlock: 2,
  SkeletonBlockHashToNumber: 3,
  SkeletonStatus: 4,
  SkeletonUnfinalizedBlockByHash: 5,
  Preimage: 6
};
var createMapDb = ({ cache }) => {
  const dbKey = (type, key) => {
    return utils.toHex(utils.concatBytes(utils.hexToBytes(utils.numberToHex(typeToId[type])), key));
  };
  return {
    ...{ _cache: cache },
    /**
     * Store a value in the database
     * @param {import('./MapDb.js').DbType} type - The type of data being stored
     * @param {Uint8Array} hash - The hash key for the data
     * @param {Uint8Array} value - The value to store
     * @returns {Promise<void>}
     */
    put(type, hash, value) {
      cache.set(dbKey(type, hash), value);
      return Promise.resolve();
    },
    /**
     * Retrieve a value from the database
     * @param {import('./MapDb.js').DbType} type - The type of data to retrieve
     * @param {Uint8Array} hash - The hash key for the data
     * @returns {Promise<Uint8Array | null>} The stored value or null if not found
     */
    get(type, hash) {
      return Promise.resolve(cache.get(dbKey(type, hash)) ?? null);
    },
    /**
     * Delete a value from the database
     * @param {import('./MapDb.js').DbType} type - The type of data to delete
     * @param {Uint8Array} hash - The hash key for the data to delete
     * @returns {Promise<void>}
     */
    delete(type, hash) {
      cache.delete(dbKey(type, hash));
      return Promise.resolve();
    },
    /**
     * Create a deep copy of the MapDb instance with a new copy of the cache
     * @returns {import('./MapDb.js').MapDb} A new MapDb instance with a copy of the data
     */
    deepCopy() {
      return createMapDb({ cache: new Map(cache) });
    }
  };
};
var ReceiptsManager = class _ReceiptsManager {
  /**
   * Creates a new ReceiptsManager instance
   * @param mapDb - The database instance for storing receipts and indexes
   * @param chain - The blockchain instance for retrieving blocks
   */
  constructor(mapDb, chain) {
    this.mapDb = mapDb;
    this.chain = chain;
  }
  /**
   * Maximum number of logs to return in getLogs
   * This prevents excessive memory usage and response size
   */
  GET_LOGS_LIMIT = 1e4;
  /**
   * Maximum size of getLogs response in megabytes
   * This prevents excessive memory usage and response size
   */
  GET_LOGS_LIMIT_MEGABYTES = 150;
  /**
   * Maximum block range that can be queried in a single getLogs call
   * This prevents excessive computational load from large queries
   */
  GET_LOGS_BLOCK_RANGE_LIMIT = 2500;
  /**
   * Creates a deep copy of this ReceiptsManager with a new chain reference
   * Useful for creating a snapshot of the current state
   *
   * @param chain - The new chain reference to use
   * @returns A new ReceiptsManager instance with copied state
   */
  deepCopy(chain) {
    return new _ReceiptsManager(this.mapDb.deepCopy(), chain);
  }
  /**
   * Saves transaction receipts to the database for a given block
   * Also builds and saves transaction hash indexes for efficient lookups
   *
   * @param block - The block containing the transactions
   * @param receipts - The transaction receipts to save
   * @returns Promise that resolves when saving is complete
   *
   * @example
   * const block = await chain.getBlock(blockNumber)
   * await receiptManager.saveReceipts(block, txReceipts)
   */
  async saveReceipts(block, receipts) {
    const encoded = this.rlp(0 /* Encode */, 0 /* Receipts */, receipts);
    await this.mapDb.put("Receipts", block.hash(), encoded);
    void this.updateIndex(0 /* Save */, 0 /* TxHash */, block);
  }
  /**
   * Deletes transaction receipts and their indexes for a given block
   * Used when removing or replacing block data
   *
   * @param block - The block whose receipts should be deleted
   * @returns Promise that resolves when deletion is complete
   *
   * @example
   * const block = await chain.getBlock(blockNumber)
   * await receiptManager.deleteReceipts(block)
   */
  async deleteReceipts(block) {
    await this.mapDb.delete("Receipts", block.hash());
    void this.updateIndex(1 /* Delete */, 0 /* TxHash */, block);
  }
  async getReceipts(blockHash, calcBloom = false, includeTxType = false) {
    const encoded = await this.mapDb.get("Receipts", blockHash);
    if (!encoded) return [];
    let receipts = this.rlp(1 /* Decode */, 0 /* Receipts */, encoded);
    if (calcBloom) {
      receipts = receipts.map((r) => {
        r.bitvector = this.logsBloom(r.logs).bitvector;
        return r;
      });
    }
    if (includeTxType) {
      const block = await blockchain.getBlock(this.chain)(blockHash);
      receipts = receipts.map((r, i) => {
        const type = block.transactions[i]?.type;
        if (type) {
          r.txType = type;
        }
        return r;
      });
    }
    return receipts;
  }
  /**
   * Retrieves a transaction receipt by transaction hash
   * Also returns additional metadata needed for JSON-RPC responses
   *
   * @param txHash - The transaction hash to look up
   * @returns Promise resolving to receipt data or null if not found
   *
   * @example
   * const receiptData = await receiptManager.getReceiptByTxHash(txHash)
   * if (receiptData) {
   *   const [receipt, blockHash, txIndex, logIndex] = receiptData
   *   // Use receipt data
   * }
   */
  async getReceiptByTxHash(txHash) {
    const txHashIndex = await this.getIndex(0 /* TxHash */, txHash);
    if (!txHashIndex) return null;
    const [blockHash, txIndex] = txHashIndex;
    const receipts = await this.getReceipts(blockHash);
    if (receipts.length === 0) return null;
    let logIndex = 0;
    receipts.slice(0, txIndex).forEach((r) => {
      logIndex += r.logs.length;
    });
    const receipt = receipts[txIndex];
    if (!receipt) {
      throw new Error("Receipt not found");
    }
    receipt.bitvector = this.logsBloom(receipt.logs).bitvector;
    return [receipt, blockHash, txIndex, logIndex];
  }
  /**
   * Retrieves logs matching the specified criteria within a block range
   * Implements the core functionality of eth_getLogs JSON-RPC method
   * Enforces size and count limits to prevent excessive resource usage
   *
   * @param from - The starting block
   * @param to - The ending block
   * @param addresses - Optional array of addresses to filter logs by
   * @param topics - Optional array of topics to filter logs by, can include arrays and nulls
   * @returns Promise resolving to array of matching logs with metadata
   *
   * @example
   * // Get all logs between blocks 100 and 200
   * const logs = await receiptManager.getLogs(block100, block200)
   *
   * // Get logs from a specific contract
   * const logs = await receiptManager.getLogs(block100, block200, [contractAddress])
   *
   * // Get logs with specific topics
   * const logs = await receiptManager.getLogs(block100, block200, undefined, [eventTopic])
   */
  async getLogs(from, to, addresses, topics = []) {
    const returnedLogs = [];
    let returnedLogsSize = 0;
    for (let i = from.header.number; i <= to.header.number; i++) {
      const block = await blockchain.getBlock(this.chain)(i);
      const receipts = await this.getReceipts(block.hash());
      if (receipts.length === 0) continue;
      let logs = [];
      let logIndex = 0;
      for (const [receiptIndex, receipt] of receipts.entries()) {
        logs.push(
          ...receipt.logs.map((log) => ({
            log,
            block,
            tx: block.transactions[receiptIndex],
            txIndex: receiptIndex,
            logIndex: logIndex++
          }))
        );
      }
      if (addresses && addresses.length > 0) {
        logs = logs.filter((l) => addresses.some((a) => utils.equalsBytes(a, l.log[0])));
      }
      if (topics.length > 0) {
        logs = logs.filter((l) => {
          for (const [i2, topic] of topics.entries()) {
            if (Array.isArray(topic)) {
              if (!topic.find((t) => utils.equalsBytes(t, l.log[1][i2]))) return false;
            } else if (!topic) ; else {
              if (!utils.equalsBytes(topic, l.log[1][i2])) return false;
            }
            return true;
          }
          return false;
        });
      }
      returnedLogs.push(...logs);
      returnedLogsSize += utils.hexToBytes(utils.stringToHex(JSON.stringify(logs))).byteLength;
      if (returnedLogs.length >= this.GET_LOGS_LIMIT || returnedLogsSize >= this.GET_LOGS_LIMIT_MEGABYTES * 1048576) {
        break;
      }
    }
    return returnedLogs;
  }
  async updateIndex(operation, type, value) {
    switch (type) {
      case 0 /* TxHash */: {
        const block = value;
        if (operation === 0 /* Save */) {
          for (const [i, tx] of block.transactions.entries()) {
            const index = [block.hash(), i];
            const encoded = this.rlp(0 /* Encode */, 2 /* TxHash */, index);
            await this.mapDb.put("TxHash", tx.hash(), encoded);
          }
        } else if (operation === 1 /* Delete */) {
          for (const tx of block.transactions) {
            await this.mapDb.delete("TxHash", tx.hash());
          }
        }
        break;
      }
      default:
        throw new Error("Unsupported index type");
    }
  }
  async getIndex(type, value) {
    switch (type) {
      case 0 /* TxHash */: {
        const encoded = await this.mapDb.get("TxHash", value);
        if (!encoded) return null;
        return this.rlp(1 /* Decode */, 2 /* TxHash */, encoded);
      }
      default:
        throw new Error("Unsupported index type");
    }
  }
  rlp(conversion, type, value) {
    switch (type) {
      case 0 /* Receipts */: {
        if (conversion === 0 /* Encode */) {
          return rlp.Rlp.encode(
            value.map((r) => [
              r.stateRoot ?? // TODO add numberToBytes to utils
              utils.hexToBytes(utils.numberToHex(r.status)),
              // TODO add numberToBytes to utils
              utils.hexToBytes(utils.numberToHex(r.cumulativeBlockGasUsed)),
              this.rlp(0 /* Encode */, 1 /* Logs */, r.logs)
            ])
          );
        }
        const decoded = rlp.Rlp.decode(value);
        return decoded.map((r) => {
          const gasUsed = r[1];
          const logs = this.rlp(1 /* Decode */, 1 /* Logs */, r[2]);
          if (r[0].length === 32) {
            return {
              stateRoot: r[0],
              cumulativeBlockGasUsed: utils.bytesToBigInt(gasUsed),
              logs
            };
          }
          return {
            status: utils.bytesToNumber(r[0]),
            cumulativeBlockGasUsed: utils.bytesToBigInt(gasUsed),
            logs
          };
        });
      }
      case 1 /* Logs */:
        if (conversion === 0 /* Encode */) {
          return rlp.Rlp.encode(value);
        }
        return rlp.Rlp.decode(value);
      case 2 /* TxHash */: {
        if (conversion === 0 /* Encode */) {
          const [blockHash2, txIndex2] = value;
          return rlp.Rlp.encode([blockHash2, utils.hexToBytes(utils.numberToHex(txIndex2))]);
        }
        const [blockHash, txIndex] = rlp.Rlp.decode(value);
        return [blockHash, utils.bytesToNumber(txIndex)];
      }
      default:
        throw new Error("Unknown rlp conversion");
    }
  }
  /**
   * Calculates a Bloom filter for a set of transaction logs
   * Used for efficient log filtering and lookups
   *
   * @param logs - The logs to include in the bloom filter
   * @returns A Bloom filter containing the log data
   * @private
   */
  logsBloom(logs) {
    const bloom = new utils.Bloom();
    for (let i = 0; i < logs.length; i++) {
      const log = logs[i];
      if (!log) {
        throw new Error("Log is empty");
      }
      bloom.add(log[0]);
      const topics = log[1];
      for (let q = 0; q < topics.length; q++) {
        bloom.add(topics[q]);
      }
    }
    return bloom;
  }
};

exports.ReceiptsManager = ReceiptsManager;
exports.createMapDb = createMapDb;
//# sourceMappingURL=index.cjs.map
//# sourceMappingURL=index.cjs.map